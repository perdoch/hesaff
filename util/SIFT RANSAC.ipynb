{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANSAC with Hessian Affine SIFT descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import ransac as _ransac\n",
    "from skimage.transform import AffineTransform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_matches(des1, des2, method='BRUTE_FORCE', is_binary_descriptor=True):\n",
    "    # create BFMatcher object    \n",
    "    if method == 'BRUTE_FORCE':\n",
    "        # BEWARE that, distance is different for binary descriptor and float descriptor. See http://answers.opencv.org/question/59996/flann-error-in-opencv-3/\n",
    "        if is_binary_descriptor: # ORB, BRIEF, BRISK\n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        else: # SIFT, SURF\n",
    "            bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "        # Match descriptors.\n",
    "        matches = bf.match(des1,des2)\n",
    "        # Sort them in the order of their distance.\n",
    "        matches = sorted(matches, key = lambda x:x.distance)                \n",
    "    elif method == 'FLANN':\n",
    "        if is_binary_descriptor:\n",
    "            raise \"Not supported yet\"\n",
    "        else:\n",
    "            # FLANN parameters    \n",
    "            FLANN_INDEX_KDTREE = 0\n",
    "            index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "            search_params = dict(checks=50)   # or pass empty dictionary\n",
    "            flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "        matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "        # Need to draw only good matches, so create a mask\n",
    "        matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "        # ratio test as per Lowe's paper\n",
    "        for i,(m,n) in enumerate(matches):\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                matchesMask[i]=[1,0]               \n",
    "\n",
    "    #     draw_params = dict(matchColor = (0,255,0),\n",
    "    #                    singlePointColor = (255,0,0),\n",
    "    #                    matchesMask = matchesMask,\n",
    "    #                    flags = 0)\n",
    "\n",
    "    #     img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,**draw_params)\n",
    "\n",
    "    #     plt.imshow(img3,),plt.show()\n",
    "    return matches\n",
    "\n",
    "def ransac(img1, img2, kp1, kp2, des1, kes2, is_binary_descriptor, match_method, description):\n",
    "    matches = get_matches(des1, des2, 'BRUTE_FORCE', is_binary_descriptor=is_binary_descriptor)    \n",
    "\n",
    "    locations_1_to_use = []\n",
    "    locations_2_to_use = []\n",
    "\n",
    "    for match in matches:\n",
    "        locations_1_to_use.append((kp1[match.queryIdx].pt[1], kp1[match.queryIdx].pt[0])) # (row, col)\n",
    "        locations_2_to_use.append((kp2[match.trainIdx].pt[1], kp2[match.trainIdx].pt[0]))\n",
    "\n",
    "    locations_1_to_use = np.array(locations_1_to_use)\n",
    "    locations_2_to_use = np.array(locations_2_to_use)\n",
    "\n",
    "    # Perform geometric verification using RANSAC.\n",
    "    model_robust, inliers = _ransac(\n",
    "      (locations_1_to_use, locations_2_to_use),\n",
    "      AffineTransform,\n",
    "      min_samples=5,\n",
    "      residual_threshold=10,\n",
    "      max_trials=1000)\n",
    "\n",
    "    inlier_idxs = np.nonzero(inliers)[0]\n",
    "\n",
    "    inlier_match = []\n",
    "    for idx in inlier_idxs:\n",
    "        inlier_match.append(matches[idx])\n",
    "\n",
    "    # Does ransac consider size and orientation of keypoints?\n",
    "    ransac_img = cv2.drawMatches(img1, kp1, img2, kp2, inlier_match, None, flags=0)    \n",
    "\n",
    "    if inliers is None:\n",
    "        score = 0\n",
    "    else:\n",
    "        score = len(inliers)\n",
    "\n",
    "    return ransac_img, score\n",
    "\n",
    "\n",
    "def draw_ransac(img1, img2, kp1, kp2, des1, kes2, is_binary_descriptor, match_method, description):\n",
    "    ransac_img, score = ransac(img1, img2, kp1, kp2, des1, kes2, is_binary_descriptor, match_method, description)\n",
    "    ransac_img = cv2.cvtColor(ransac_img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.title(description)\n",
    "    plt.imshow(ransac_img)\n",
    "    plt.show()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def parse_sift_output(target_path):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "        kp: keypoint of hessian affine descriptor. location, orientation etc... OpenCV KeyPoint format. \n",
    "        des: 128d uint8 np array\n",
    "    \"\"\"\n",
    "    import os\n",
    "    # print(os.listdir(\"./sample\"))\n",
    "    kp = []\n",
    "    des = []\n",
    "    with open(target_path, \"r\") as f:\n",
    "        lines = list(map(lambda x: x.strip(), f.readlines()))\n",
    "        num_descriptor = int(lines[1])\n",
    "        lines = lines[2:]\n",
    "        for i in range(num_descriptor):\n",
    "            # print(i, lines[i])\n",
    "            val = lines[i].split(\" \")\n",
    "            x = float(val[0])\n",
    "            y = float(val[1])\n",
    "            a = float(val[2])\n",
    "            b = float(val[3])\n",
    "            c = float(val[4])\n",
    "            # TODO: generate ellipse shaped key point\n",
    "            # Refer: https://math.stackexchange.com/questions/1447730/drawing-ellipse-from-eigenvalue-eigenvector\n",
    "            # Refer: http://www.robots.ox.ac.uk/~vgg/research/affine/det_eval_files/display_features.m\n",
    "            # Refer: http://www.robots.ox.ac.uk/~vgg/research/affine/detectors.html\n",
    "            key_point = cv2.KeyPoint(x, y, 1)\n",
    "            sift_descriptor = np.array(list(map(lambda x: int(x), val[5:])), dtype=np.uint8)\n",
    "            kp.append(key_point)\n",
    "            des.append(sift_descriptor)\n",
    "        \n",
    "    \n",
    "    return kp, np.array(des)\n",
    "\n",
    "kp1, des1 = parse_sift_output(target_path=\"../sample/all_souls_000026.jpg.hesaff.sift\")\n",
    "kp2, des2 = parse_sift_output(target_path=\"../sample/all_souls_000055.jpg.hesaff.sift\")\n",
    "\n",
    "\n",
    "img1 = cv2.imread('../sample/all_souls_000026.jpg') # query image\n",
    "img2 = cv2.imread('../sample/all_souls_000055.jpg')\n",
    "\n",
    "_, num_inliner = ransac(img1, img2, kp1, kp2, des1, des2, False, 'BRUTE_FORCE', None)\n",
    "print('num_inliner:', num_inliner)\n",
    "\n",
    "# ransac and plot\n",
    "draw_ransac(img1, img2, kp1, kp2, des1, des2, False, 'BRUTE_FORCE', None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
